{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c90ddf",
   "metadata": {},
   "source": [
    "# 04 - Real World NumPy Usage\n",
    "\n",
    "Now we apply NumPy to real data-like scenarios:\n",
    "\n",
    "- Data cleaning & preprocessing\n",
    "- Feature scaling\n",
    "- Missing value handling\n",
    "- Combining arrays\n",
    "- Random sampling (critical for ML training/validation splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdc20d9",
   "metadata": {},
   "source": [
    "1) Generating synthetic dataset (like ML problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b52c475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54.96714153, 48.61735699, 56.47688538],\n",
       "       [65.23029856, 47.65846625, 47.65863043],\n",
       "       [65.79212816, 57.67434729, 45.30525614],\n",
       "       [55.42560044, 45.36582307, 45.34270246],\n",
       "       [52.41962272, 30.86719755, 32.75082167],\n",
       "       [44.37712471, 39.8716888 , 53.14247333],\n",
       "       [40.91975924, 35.87696299, 64.65648769],\n",
       "       [47.742237  , 50.67528205, 35.75251814],\n",
       "       [44.55617275, 51.1092259 , 38.49006423],\n",
       "       [53.75698018, 43.9936131 , 47.0830625 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Random dataset: 100 rows, 3 features\n",
    "np.random.seed(42)\n",
    "data = np.random.randn(100, 3) * 10 + 50\n",
    "\n",
    "data[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efab16b",
   "metadata": {},
   "source": [
    "You now have:\n",
    "\n",
    "100 samples (rows)\n",
    "\n",
    "3 features (columns)\n",
    "\n",
    "This mimics real numeric data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a667ff",
   "metadata": {},
   "source": [
    "2) Feature Scaling (Standardization)\n",
    "\n",
    "This is used in EVERY ML model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc563de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means after scaling: [5.22359933e-16 9.99200722e-16 1.95177208e-15]\n",
      "Std dev after scaling: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "mean = data.mean(axis=0)\n",
    "std = data.std(axis=0)\n",
    "\n",
    "data_scaled = (data - mean) / std\n",
    "\n",
    "print(\"Means after scaling:\", data_scaled.mean(axis=0))\n",
    "print(\"Std dev after scaling:\", data_scaled.std(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec78f3",
   "metadata": {},
   "source": [
    "If this doesn’t click → you’ll fail in ML interviews.\n",
    "This is core."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdaf5b8",
   "metadata": {},
   "source": [
    "3) Min-Max Normalization (used in neural networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a4984bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59784738, 0.55850332, 0.50481969],\n",
       "       [0.84841079, 0.54124443, 0.36857733],\n",
       "       [0.86212723, 0.72151827, 0.33221761],\n",
       "       [0.60904014, 0.49997961, 0.33279616],\n",
       "       [0.53565259, 0.23902174, 0.13825114]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val = data.min(axis=0)\n",
    "max_val = data.max(axis=0)\n",
    "\n",
    "data_norm = (data - min_val) / (max_val - min_val)\n",
    "\n",
    "data_norm[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870294c4",
   "metadata": {},
   "source": [
    "Difference:\n",
    "\n",
    "Standardization → mean 0, std 1 (used for ML models)\n",
    "\n",
    "Min-Max → range [0,1] (used for neural networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c16ab",
   "metadata": {},
   "source": [
    "4) Handling Missing Data\n",
    "\n",
    "Simulate missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc8a7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54.96714153         nan 56.47688538]\n",
      " [65.23029856         nan 47.65863043]\n",
      " [65.79212816         nan 45.30525614]\n",
      " [55.42560044         nan 45.34270246]\n",
      " [52.41962272         nan 32.75082167]\n",
      " [44.37712471 39.8716888  53.14247333]\n",
      " [40.91975924 35.87696299 64.65648769]\n",
      " [47.742237   50.67528205 35.75251814]\n",
      " [44.55617275 51.1092259  38.49006423]\n",
      " [53.75698018 43.9936131  47.0830625 ]]\n"
     ]
    }
   ],
   "source": [
    "data_missing = data.copy()\n",
    "data_missing[0:5, 1] = np.nan  # corrupt one feature\n",
    "\n",
    "print(data_missing[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4394bbb3",
   "metadata": {},
   "source": [
    "Replace missing values with column mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d61d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mean = np.nanmean(data_missing, axis=0)\n",
    "idxs = np.where(np.isnan(data_missing))\n",
    "data_missing[idxs] = np.take(col_mean, idxs[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a1d6f1",
   "metadata": {},
   "source": [
    "This is exactly what pandas .fillna() does under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a13a4",
   "metadata": {},
   "source": [
    "5) Train-Test Split (But without sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0facfd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 3), (20, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(data))\n",
    "\n",
    "train_size = int(0.8 * len(data))\n",
    "train_idx = indices[:train_size]\n",
    "test_idx = indices[train_size:]\n",
    "\n",
    "train_data = data[train_idx]\n",
    "test_data = data[test_idx]\n",
    "\n",
    "train_data.shape, test_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80e70a1",
   "metadata": {},
   "source": [
    "This is the actual logic behind train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d65844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
